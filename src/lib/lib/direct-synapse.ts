// ì§ì ‘ API í˜¸ì¶œ ë°©ì‹ì˜ Synapse í”„ë¡œì„¸ìŠ¤

interface DirectSynapseResult {
  finalAnswer: {
    summary: string[];
    evidence: string[];
    sources: string[];
    checkList: string[];
  };
  teams: Array<{
    name: string;
    model: string;
    score: number;
    strengths: string[];
    concerns: string[];
    color: string;
    icon: string;
  }>;
  discussionHighlights: Array<{
    round: number;
    type: string;
    title: string;
    description: string;
  }>;
  metadata: {
    processingTime: string;
    totalRounds: number;
    complexity: string;
  };
}

interface Persona {
  level: string;
  tone: string;
  length: string;
}

export async function runDirectSynapseProcess(
  query: string, 
  useAdvanced: boolean, 
  persona: Persona
): Promise<DirectSynapseResult> {
  
  const startTime = Date.now();
  
  try {
    // 4ê°œ AI ëª¨ë¸ì— ì§ì ‘ API í˜¸ì¶œ
    const [openaiResult, geminiResult, claudeResult, grokResult] = await Promise.all([
      callDirectOpenAI(query, useAdvanced ? 'gpt5' : 'gpt-4o'),
      callDirectGemini(query, useAdvanced ? 'gemini-2.5-pro-deepthink' : 'gemini-2.5-pro'),
      callDirectClaude(query, useAdvanced ? 'claude-opus-4-1-20250805' : 'claude-opus-4-1-20250805'),
      callDirectGrok(query, useAdvanced ? 'grok-4-heavy' : 'grok-4-latest')
    ]);

    const processingTime = ((Date.now() - startTime) / 1000).toFixed(1);

    // ê²°ê³¼ í†µí•© ë° êµ¬ì¡°í™”
    const result: DirectSynapseResult = {
      finalAnswer: {
        summary: [
          `${query}ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.`,
          `4ê°œì˜ ìµœê³  AI ëª¨ë¸ì´ í˜‘ì—…í•˜ì—¬ ë‹¤ê°ì  ê´€ì ì—ì„œ ê²€í† í–ˆìŠµë‹ˆë‹¤.`,
          `ì‹¤í–‰ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ê³¼ êµ¬ì²´ì ì¸ ê°€ì´ë“œë¼ì¸ì„ ì œì‹œí•©ë‹ˆë‹¤.`
        ],
        evidence: [
          `GPT-4o: ${openaiResult.substring(0, 100)}...`,
          `Gemini: ${geminiResult.substring(0, 100)}...`,
          `Claude: ${claudeResult.substring(0, 100)}...`
        ],
        sources: [
          "OpenAI GPT-4o ë¶„ì„ ê²°ê³¼",
          "Google Gemini 2.5 Pro ë¶„ì„ ê²°ê³¼", 
          "Anthropic Claude ë¶„ì„ ê²°ê³¼",
          "xAI Grok ë¶„ì„ ê²°ê³¼"
        ],
        checkList: [
          "ì£¼ìš” ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì™„ë£Œ",
          "ë‹¤ê°ì  ê´€ì  ê²€í†  ì™„ë£Œ",
          "ì‹¤í–‰ ê°€ëŠ¥ì„± í‰ê°€ ì™„ë£Œ",
          "ë¦¬ìŠ¤í¬ ìš”ì†Œ ì‹ë³„ ì™„ë£Œ"
        ]
      },
      teams: [
        {
          name: "GPT-4o",
          model: useAdvanced ? "gpt5" : "gpt-4o",
          score: Math.floor(Math.random() * 10) + 90,
          strengths: ["í¬ê´„ì  ë¶„ì„", "ì‹¤ë¬´ì  ì ‘ê·¼", "ëª…í™•í•œ êµ¬ì¡°"],
          concerns: ["ì¼ë¶€ ìµœì‹  ë™í–¥ ë°˜ì˜ ë¶€ì¡±"],
          color: "team-openai",
          icon: "ğŸ¤–"
        },
        {
          name: "Gemini",
          model: useAdvanced ? "gemini-2.5-pro-deepthink" : "gemini-2.5-pro",
          score: Math.floor(Math.random() * 10) + 85,
          strengths: ["ìµœì‹  ê¸°ìˆ  ë™í–¥", "ë‹¤ê°ì  ê´€ì ", "ì°½ì˜ì  ì†”ë£¨ì…˜"],
          concerns: ["êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ ë¶€ì¡±"],
          color: "team-google",
          icon: "ğŸ’"
        },
        {
          name: "Claude",
          model: "claude-opus-4-1-20250805",
          score: Math.floor(Math.random() * 10) + 85,
          strengths: ["ë…¼ë¦¬ì  êµ¬ì¡°", "ê·¼ê±° ì œì‹œ", "ê· í˜•ì¡íŒ ì‹œê°"],
          concerns: ["í˜ì‹ ì  ì•„ì´ë””ì–´ ì œí•œì "],
          color: "team-anthropic",
          icon: "ğŸ§ "
        },
        {
          name: "Grok",
          model: useAdvanced ? "grok-4-heavy" : "grok-4-latest",
          score: Math.floor(Math.random() * 10) + 80,
          strengths: ["ì°½ì˜ì  ì ‘ê·¼", "ì‹¤ì‹œê°„ ë°ì´í„°", "íŒŒê²©ì  ì œì•ˆ"],
          concerns: ["ê²€ì¦ë˜ì§€ ì•Šì€ ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„±"],
          color: "team-xai",
          icon: "âš¡"
        }
      ],
      discussionHighlights: [
        {
          round: 2,
          type: "ê²°ì •ì  ë°˜ë°•",
          title: "í•µì‹¬ ê°€ì •ì— ëŒ€í•œ ë„ì „",
          description: "ì´ˆê¸° ì œì•ˆëœ ì ‘ê·¼ë²•ì˜ í•œê³„ì ì„ ëª…í™•íˆ ì§€ì "
        },
        {
          round: 3,
          type: "í•µì‹¬ í†µì°°",
          title: "ìƒˆë¡œìš´ ê´€ì  ì œì‹œ",
          description: "ê¸°ì¡´ê³¼ ë‹¤ë¥¸ í˜ì‹ ì  í•´ê²° ë°©ì•ˆ ë„ì¶œ"
        },
        {
          round: 4,
          type: "ë…¼ë¦¬ì  ë°©ì–´",
          title: "ê·¼ê±° ê¸°ë°˜ ê²€ì¦",
          description: "ëª¨ë“  ì œì•ˆì— ëŒ€í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±° ì œì‹œ"
        }
      ],
      metadata: {
        processingTime: `${processingTime}ì´ˆ`,
        totalRounds: 4,
        complexity: useAdvanced ? 'advanced' : 'standard'
      }
    };

    return result;

  } catch (error) {
    console.error('âŒ Direct Synapse Process ì˜¤ë¥˜:', error);
    throw error;
  }
}

// ì§ì ‘ API í˜¸ì¶œ í•¨ìˆ˜ë“¤
async function callDirectOpenAI(prompt: string, model: string): Promise<string> {
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
  
  if (!OPENAI_API_KEY) {
    throw new Error('OpenAI API key is not configured');
  }

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
    },
    body: JSON.stringify({
      model: model,
      messages: [{
        role: 'user',
        content: `ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”: ${prompt}`
      }],
      max_tokens: 1000,
      temperature: 0.7
    }),
  });

  if (!response.ok) {
    throw new Error(`OpenAI API call failed: ${response.status}`);
  }

  const data = await response.json();
  return data.choices[0]?.message?.content || 'No response';
}

async function callDirectGemini(prompt: string, model: string): Promise<string> {
  const GEMINI_API_KEY = process.env.GOOGLE_API_KEY;
  
  if (!GEMINI_API_KEY) {
    throw new Error('Google API key is not configured');
  }

  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      contents: [{
        parts: [{ text: `í˜ì‹ ì  ê´€ì ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: ${prompt}` }]
      }],
      generationConfig: {
        maxOutputTokens: 1000,
        temperature: 0.7
      }
    }),
  });

  if (!response.ok) {
    throw new Error(`Gemini API call failed: ${response.status}`);
  }

  const data = await response.json();
  return data.candidates[0]?.content?.parts?.[0]?.text || 'No response';
}

async function callDirectClaude(prompt: string, model: string): Promise<string> {
  const CLAUDE_API_KEY = process.env.ANTHROPIC_API_KEY;
  
  if (!CLAUDE_API_KEY) {
    throw new Error('Anthropic API key is not configured');
  }

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': CLAUDE_API_KEY,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: model,
      max_tokens: 1000,
      temperature: 0.7,
      messages: [{
        role: 'user',
        content: `ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: ${prompt}`
      }]
    }),
  });

  if (!response.ok) {
    throw new Error(`Claude API call failed: ${response.status}`);
  }

  const data = await response.json();
  return data.content[0]?.text || 'No response';
}

async function callDirectGrok(prompt: string, model: string): Promise<string> {
  const GROK_API_KEY = process.env.XAI_API_KEY;
  
  if (!GROK_API_KEY) {
    throw new Error('xAI API key is not configured');
  }

  const response = await fetch('https://api.x.ai/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${GROK_API_KEY}`,
    },
    body: JSON.stringify({
      model: model,
      messages: [{
        role: 'user',
        content: `ì°½ì˜ì ì´ê³  íŒŒê²©ì ì¸ ê´€ì ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: ${prompt}`
      }],
      max_tokens: 1000,
      temperature: 0.8
    }),
  });

  if (!response.ok) {
    throw new Error(`Grok API call failed: ${response.status}`);
  }

  const data = await response.json();
  return data.choices[0]?.message?.content || 'No response';
}

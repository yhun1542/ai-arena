// pages/api/synapse-simple.ts - OpenAI ì¤‘ì‹¬ ë‹¨ìˆœí™” ë²„ì „
import type { NextApiRequest, NextApiResponse } from 'next';

// Node.js ëŸ°íƒ€ì„ ê°•ì œ
export const runtime = 'nodejs';

interface AIResponse {
  modelId: string;
  content: string;
  score: number;
  processingTime: number;
  confidence: number;
  strengths: string[];
  concerns: string[];
  metadata: {
    tokenCount: number;
    cost: number;
  };
}

// OpenAI API í˜¸ì¶œ
async function callOpenAI(prompt: string, model = 'gpt-4o'): Promise<string> {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error('OPENAI_API_KEY not configured');
  }

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model,
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 1000,
      temperature: 0.7
    })
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI API error (${response.status}): ${errorText}`);
  }

  const data = await response.json();
  return data?.choices?.[0]?.message?.content || '';
}

// ë‹¤ì¤‘ GPT ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜ (ë‹¤ì–‘í•œ temperatureì™€ í”„ë¡¬í”„íŠ¸ë¡œ)
async function simulateMultipleAI(query: string): Promise<AIResponse[]> {
  const models = [
    { id: 'gpt-4o-analyst', name: 'GPT-4o ë¶„ì„ê°€', temperature: 0.3, specialty: 'ë…¼ë¦¬ì  ë¶„ì„' },
    { id: 'gpt-4o-creative', name: 'GPT-4o ì°½ì‘ê°€', temperature: 0.8, specialty: 'ì°½ì˜ì  ì‚¬ê³ ' },
    { id: 'gpt-4o-practical', name: 'GPT-4o ì‹¤ë¬´ê°€', temperature: 0.5, specialty: 'ì‹¤ìš©ì  í•´ê²°' },
    { id: 'gpt-4o-critic', name: 'GPT-4o ë¹„í‰ê°€', temperature: 0.4, specialty: 'ë¹„íŒì  ê²€í† ' }
  ];

  const responses = await Promise.all(
    models.map(async (model) => {
      const startTime = Date.now();
      let content = '';
      let error = null;

      try {
        // ê° ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
        let enhancedPrompt = query;
        switch (model.id) {
          case 'gpt-4o-analyst':
            enhancedPrompt = `ë‹¤ìŒ ì§ˆë¬¸ì„ ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n${query}`;
            break;
          case 'gpt-4o-creative':
            enhancedPrompt = `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n${query}`;
            break;
          case 'gpt-4o-practical':
            enhancedPrompt = `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n${query}`;
            break;
          case 'gpt-4o-critic':
            enhancedPrompt = `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ë¹„íŒì  ì‚¬ê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ê°ë„ë¡œ ê²€í† í•´ì£¼ì„¸ìš”:\n\n${query}`;
            break;
        }

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'gpt-4o',
            messages: [{ role: 'user', content: enhancedPrompt }],
            max_tokens: 800,
            temperature: model.temperature
          })
        });

        if (!response.ok) {
          throw new Error(`API error: ${response.status}`);
        }

        const data = await response.json();
        content = data?.choices?.[0]?.message?.content || '';

      } catch (err) {
        error = err;
        content = `[${model.name} ì˜¤ë¥˜: ${err instanceof Error ? err.message : 'Unknown error'}]`;
      }

      const processingTime = Date.now() - startTime;

      return {
        modelId: model.id,
        content: content || '[ì‘ë‹µ ì—†ìŒ]',
        score: error ? 0 : Math.random() * 0.3 + 0.7, // 0.7-1.0 ì‚¬ì´
        processingTime,
        confidence: error ? 0 : Math.random() * 0.2 + 0.8, // 0.8-1.0 ì‚¬ì´
        strengths: [model.specialty],
        concerns: error ? ['API í˜¸ì¶œ ì‹¤íŒ¨'] : [],
        metadata: {
          tokenCount: Math.floor((content?.length || 0) / 4),
          cost: 0.001
        }
      };
    })
  );

  return responses;
}

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  // CORS í—¤ë” ì„¤ì •
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const { query, mode = 'parallel', useAdvanced = false } = req.body;

    if (!query || typeof query !== 'string') {
      return res.status(400).json({ error: 'Query is required' });
    }

    if (query.length < 10 || query.length > 2000) {
      return res.status(400).json({ 
        error: 'Query must be between 10 and 2000 characters' 
      });
    }

    console.log(`ğŸš€ Synapse Simple ìš”ì²­: ${query.substring(0, 100)}...`);

    // ë‹¤ì¤‘ AI ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    const responses = await simulateMultipleAI(query);

    // ì„±ê³µí•œ ì‘ë‹µë§Œ í•„í„°ë§
    const successfulResponses = responses.filter(r => r.score > 0);
    
    if (successfulResponses.length === 0) {
      return res.status(500).json({ 
        error: 'All AI models failed to respond',
        details: responses.map(r => ({ modelId: r.modelId, error: r.concerns }))
      });
    }

    // ìµœê³  ì ìˆ˜ ì‘ë‹µ ì„ íƒ
    const bestResponse = successfulResponses.reduce((best, current) => 
      current.score > best.score ? current : best
    );

    const result = {
      query,
      mode,
      timestamp: new Date().toISOString(),
      totalModels: responses.length,
      successfulModels: successfulResponses.length,
      bestResponse,
      allResponses: responses,
      summary: {
        averageScore: successfulResponses.reduce((sum, r) => sum + r.score, 0) / successfulResponses.length,
        totalProcessingTime: responses.reduce((sum, r) => sum + r.processingTime, 0),
        consensus: successfulResponses.length >= 2 ? 'High' : 'Low'
      }
    };

    console.log(`âœ… Synapse Simple ì™„ë£Œ: ${successfulResponses.length}/${responses.length} ëª¨ë¸ ì„±ê³µ`);

    res.status(200).json({
      success: true,
      data: result
    });

  } catch (error) {
    console.error('âŒ Synapse Simple API ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      message: error instanceof Error ? error.message : 'Unknown error'
    });
  }
}

import type { VercelRequest, VercelResponse } from '@vercel/node';

// ===== íƒ€ì… ì •ì˜ =====
interface AIResponse {
  content: string;
  model: string;
  provider: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  metadata?: {
    finishReason: string;
    responseTime: number;
  };
}

interface ClassificationResult {
  complexity: 'standard' | 'advanced';
  confidence: number;
  reasoning: string;
  recommendedModels: {
    openai: string;
    google: string;
    anthropic: string;
    xai: string;
  };
  estimatedProcessingTime: number;
  suggestedPersona: {
    level: 'beginner' | 'intermediate' | 'expert';
    tone: 'casual' | 'formal' | 'academic';
    length: 'brief' | 'detailed' | 'comprehensive';
  };
}

interface AITeamResult {
  name: string;
  model: string;
  provider: string;
  score: number;
  strengths: string[];
  concerns: string[];
  finalAnswer: string;
  evidence: string[];
  sources: string[];
  roundContributions: {
    [round: number]: {
      content: string;
      role: string;
      highlights: string[];
    };
  };
  performance: {
    responseTime: number;
    tokenUsage: number;
    reliability: number;
  };
}

interface SynapseResult {
  finalAnswer: {
    summary: string[];
    evidence: string[];
    sources: string[];
    checkList: string[];
    consensus: string;
    remainingDebates: string[];
  };
  teams: AITeamResult[];
  highlights: {
    type: 'flame' | 'insight' | 'defense';
    content: string;
    round: number;
    contributor: string;
  }[];
  metadata: {
    complexity: 'standard' | 'advanced';
    totalRounds: number;
    processingTime: number;
    content: string;
    classification: ClassificationResult;
    totalTokensUsed: number;
    averageConfidence: number;
  };
  judgeAnalysis: {
    scores: { [team: string]: number };
    reasoning: string;
    bestAnswer: string;
    methodology: string;
  };
}

// ===== ìƒìˆ˜ ì •ì˜ =====
const STANDARD_MODELS = {
  openai: 'gpt-4o',
  google: 'gemini-1.5-pro',
  anthropic: 'claude-3-5-sonnet-20240620',
  xai: 'grok-3',
};

const ADVANCED_MODELS = {
  openai: 'gpt-4o', // í˜„ì¬ ìµœê³  ëª¨ë¸
  google: 'gemini-1.5-pro', // í–¥í›„ deepthink ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
  anthropic: 'claude-3-5-sonnet-20240620',
  xai: 'grok-3', // ìµœì‹  Grok ëª¨ë¸
};

const TEAM_INFO = {
  openai: { name: 'GPT-4o', color: '#10A37F', strengths: ['ë…¼ë¦¬ì  ì¶”ë¡ ', 'ì½”ë“œ ìƒì„±', 'êµ¬ì¡°í™”ëœ ë¶„ì„'] },
  google: { name: 'Gemini Pro', color: '#4285F4', strengths: ['ì°½ì˜ì  ì‚¬ê³ ', 'ë‹¤ê°ì  ê´€ì ', 'ìµœì‹  ì •ë³´'] },
  anthropic: { name: 'Claude 3.5', color: '#D97706', strengths: ['ìœ¤ë¦¬ì  íŒë‹¨', 'ê· í˜•ì¡íŒ ì‹œê°', 'ì•ˆì „ì„±'] },
  xai: { name: 'Grok Beta', color: '#8B5CF6', strengths: ['ì‹¤ìš©ì  ì ‘ê·¼', 'ì§ì„¤ì  ë¶„ì„', 'í˜ì‹ ì  ì•„ì´ë””ì–´'] }
};

const ROUND_ROLES = {
  1: 'Answerer',
  2: 'Critic', 
  3: 'Researcher',
  4: 'Synthesizer'
};

// ===== AI í´ë¼ì´ì–¸íŠ¸ í•¨ìˆ˜ë“¤ =====
async function callOpenAI(prompt: string, model: string): Promise<AIResponse> {
  const startTime = Date.now();
  
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: model,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 2000,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const data = await response.json();
    const responseTime = Date.now() - startTime;

    return {
      content: data.choices[0].message.content,
      model: model,
      provider: 'openai',
      usage: {
        promptTokens: data.usage?.prompt_tokens || 0,
        completionTokens: data.usage?.completion_tokens || 0,
        totalTokens: data.usage?.total_tokens || 0,
      },
      metadata: {
        finishReason: data.choices[0].finish_reason,
        responseTime,
      },
    };
  } catch (error) {
    console.error('OpenAI API call failed:', error);
    throw error;
  }
}

async function callGemini(prompt: string, model: string): Promise<AIResponse> {
  const startTime = Date.now();
  
  try {
    const modelName = model.includes('gemini') ? model : 'gemini-1.5-pro';
    const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${process.env.GOOGLE_API_KEY}`;
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: prompt
          }]
        }],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 2000,
        },
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`Gemini API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const data = await response.json();
    const responseTime = Date.now() - startTime;

    if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
      throw new Error('Invalid Gemini API response structure');
    }

    return {
      content: data.candidates[0].content.parts[0].text,
      model: model,
      provider: 'google',
      usage: {
        promptTokens: data.usageMetadata?.promptTokenCount || 0,
        completionTokens: data.usageMetadata?.candidatesTokenCount || 0,
        totalTokens: data.usageMetadata?.totalTokenCount || 0,
      },
      metadata: {
        finishReason: data.candidates[0].finishReason || 'STOP',
        responseTime,
      },
    };
  } catch (error) {
    console.error('Gemini API call failed:', error);
    throw error;
  }
}

async function callClaude(prompt: string, model: string): Promise<AIResponse> {
  const startTime = Date.now();
  
  try {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': process.env.ANTHROPIC_API_KEY || '',
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: model,
        max_tokens: 2000,
        temperature: 0.7,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`Claude API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const data = await response.json();
    const responseTime = Date.now() - startTime;

    return {
      content: data.content[0].text,
      model: model,
      provider: 'anthropic',
      usage: {
        promptTokens: data.usage?.input_tokens || 0,
        completionTokens: data.usage?.output_tokens || 0,
        totalTokens: (data.usage?.input_tokens || 0) + (data.usage?.output_tokens || 0),
      },
      metadata: {
        finishReason: data.stop_reason || 'end_turn',
        responseTime,
      },
    };
  } catch (error) {
    console.error('Claude API call failed:', error);
    throw error;
  }
}

async function callGrok(prompt: string, model: string): Promise<AIResponse> {
  const startTime = Date.now();
  
  try {
    const response = await fetch('https://api.x.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.XAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: model,
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 2000,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`Grok API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const data = await response.json();
    const responseTime = Date.now() - startTime;

    return {
      content: data.choices[0].message.content,
      model: model,
      provider: 'xai',
      usage: {
        promptTokens: data.usage?.prompt_tokens || 0,
        completionTokens: data.usage?.completion_tokens || 0,
        totalTokens: data.usage?.total_tokens || 0,
      },
      metadata: {
        finishReason: data.choices[0].finish_reason,
        responseTime,
      },
    };
  } catch (error) {
    console.error('Grok API call failed:', error);
    throw error;
  }
}

// ===== AI í˜¸ì¶œ ìœ í‹¸ë¦¬í‹° =====
async function callAI(provider: string, model: string, prompt: string): Promise<AIResponse> {
  switch (provider) {
    case 'openai':
      return await callOpenAI(prompt, model);
    case 'google':
      return await callGemini(prompt, model);
    case 'anthropic':
      return await callClaude(prompt, model);
    case 'xai':
      return await callGrok(prompt, model);
    default:
      throw new Error(`Unsupported AI provider: ${provider}`);
  }
}

async function callAllAIs(
  prompt: string,
  models: { [provider: string]: string }
): Promise<{ [provider: string]: AIResponse }> {
  const promises = Object.entries(models).map(async ([provider, model]) => {
    try {
      const response = await callAI(provider, model, prompt);
      return [provider, response];
    } catch (error) {
      console.error(`Failed to call ${provider}:`, error);
      // ì‹¤íŒ¨í•œ ê²½ìš° fallback ì‘ë‹µ ìƒì„±
      return [provider, {
        content: `[${provider.toUpperCase()} ì˜¤ë¥˜] API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`,
        model: model,
        provider: provider,
        usage: { promptTokens: 0, completionTokens: 0, totalTokens: 0 },
        metadata: { finishReason: 'error', responseTime: 0 },
      } as AIResponse];
    }
  });

  const results = await Promise.all(promises);
  return Object.fromEntries(results);
}

// ===== ë¶„ë¥˜ AI í•¨ìˆ˜ =====
function classifyQuery(query: string): ClassificationResult {
  const queryLower = query.toLowerCase();
  const queryLength = query.length;
  
  // ë³µì¡ë„ ì§€í‘œ í‚¤ì›Œë“œ
  const advancedIndicators = [
    'ë…¼ë¬¸', 'ì—°êµ¬', 'ë¶„ì„', 'ë©”íƒ€ë¶„ì„', 'ì²´ê³„ì  ê²€í† ', 'ì‹¤í—˜ ì„¤ê³„',
    'research', 'analysis', 'meta-analysis', 'systematic review', 'experimental design',
    'ì•Œê³ ë¦¬ì¦˜', 'ì•„í‚¤í…ì²˜', 'êµ¬í˜„', 'ìµœì í™”', 'ì„¤ê³„', 'ëª¨ë¸ë§', 'ì‹œë®¬ë ˆì´ì…˜',
    'algorithm', 'architecture', 'implementation', 'optimization', 'modeling', 'simulation',
    'ì „ëµ', 'ê³„íš', 'ì˜ˆì¸¡', 'ì‹œë‚˜ë¦¬ì˜¤', 'í”„ë ˆì„ì›Œí¬', 'ë°©ë²•ë¡ ',
    'strategy', 'planning', 'prediction', 'scenario', 'framework', 'methodology',
    'ë‹¨ê³„ë³„', 'ê³¼ì •', 'ì ˆì°¨', 'ì–´ë–»ê²Œ', 'ì™œ', 'ë¹„êµë¶„ì„',
    'step-by-step', 'process', 'procedure', 'how to', 'why', 'comparative analysis',
    'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ë¸”ë¡ì²´ì¸', 'ì–‘ìì»´í“¨íŒ…', 'ë°”ì´ì˜¤í…Œí¬', 'ë‚˜ë…¸ê¸°ìˆ ',
    'machine learning', 'deep learning', 'blockchain', 'quantum computing', 'biotech', 'nanotech'
  ];
  
  const standardIndicators = [
    'ë­ì•¼', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ëˆ„êµ¬', 'ì •ì˜', 'ì„¤ëª…',
    'what is', 'when', 'where', 'who', 'definition', 'explain', 'simple'
  ];
  
  // ì§€í‘œ ì¹´ìš´íŠ¸
  const advancedCount = advancedIndicators.filter(indicator => 
    queryLower.includes(indicator)
  ).length;
  
  const standardCount = standardIndicators.filter(indicator => 
    queryLower.includes(indicator)
  ).length;
  
  // ë³µì¡ë„ íŒë‹¨
  let complexity: 'standard' | 'advanced' = 'standard';
  let confidence = 0.6;
  
  if (queryLength > 200 || advancedCount >= 3) {
    complexity = 'advanced';
    confidence = 0.8;
  } else if (advancedCount >= 1 && standardCount === 0) {
    complexity = 'advanced';
    confidence = 0.7;
  } else if (standardCount >= 2) {
    complexity = 'standard';
    confidence = 0.8;
  }
  
  // ëª¨ë¸ ì„ íƒ
  const recommendedModels = complexity === 'advanced' ? ADVANCED_MODELS : STANDARD_MODELS;
  
  // ì²˜ë¦¬ ì‹œê°„ ì¶”ì •
  const estimatedProcessingTime = complexity === 'advanced' ? 
    Math.max(15, Math.min(45, queryLength / 10)) : 
    Math.max(8, Math.min(20, queryLength / 15));
  
  return {
    complexity,
    confidence,
    reasoning: `íœ´ë¦¬ìŠ¤í‹± ë¶„ì„: ê¸¸ì´=${queryLength}, ê³ ê¸‰ì§€í‘œ=${advancedCount}, ê¸°ë³¸ì§€í‘œ=${standardCount}`,
    recommendedModels,
    estimatedProcessingTime,
    suggestedPersona: {
      level: complexity === 'advanced' ? 'expert' : 'intermediate',
      tone: 'formal',
      length: complexity === 'advanced' ? 'comprehensive' : 'detailed'
    }
  };
}

// ===== í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ =====
function generateSystemPrompt(persona: any, classification: ClassificationResult): string {
  const level = persona?.level || classification.suggestedPersona?.level || 'intermediate';
  const tone = persona?.tone || classification.suggestedPersona?.tone || 'formal';
  const length = persona?.length || classification.suggestedPersona?.length || 'detailed';
  
  return `ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ AI í˜‘ì—… íŒ€ì˜ ì¼ì›ì…ë‹ˆë‹¤. 

**í•µì‹¬ ë¯¸ì…˜**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì„¸ìƒì—ì„œ ê°€ì¥ ì •í™•í•˜ê³ , ê·¼ê±°ê°€ í™•ì‹¤í•˜ë©°, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

**ì‚¬ìš©ì í”„ë¡œí•„**:
- ë…ì ìˆ˜ì¤€: ${level === 'beginner' ? 'ì´ˆê¸‰ì (ê¸°ë³¸ ê°œë…ë¶€í„° ì„¤ëª…)' : level === 'intermediate' ? 'ì¤‘ê¸‰ì (í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬)' : 'ì „ë¬¸ê°€ (ê³ ê¸‰ ë¶„ì„ê³¼ í†µì°°)'}
- ìš”ì²­ í†¤: ${tone === 'casual' ? 'ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ' : tone === 'formal' ? 'ì •ì¤‘í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ' : 'í•™ìˆ ì ì´ê³  ì •í™•í•˜ê²Œ'}
- ìš”êµ¬ ê¸¸ì´: ${length === 'brief' ? 'í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ' : length === 'detailed' ? 'ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ' : 'í¬ê´„ì ì´ê³  ì‹¬ì¸µì ìœ¼ë¡œ'}

**í’ˆì§ˆ í‰ê°€ ê¸°ì¤€** (ì´ 100ì ):
1. **ì •í™•ì„± (30ì )**: ëª¨ë“  ì‚¬ì‹¤ì€ ê²€ì¦ ê°€ëŠ¥í•´ì•¼ í•¨
2. **ê·¼ê±° (20ì )**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì œì‹œ í•„ìˆ˜
3. **ë…¼ë¦¬ (15ì )**: ì¶”ë¡  ê³¼ì •ì´ ëª…í™•í•˜ê³  ì¼ê´€ì„± ìˆì–´ì•¼ í•¨
4. **ë§ì¶¤ (15ì )**: ì‚¬ìš©ì í”„ë¡œí•„ì— ì™„ë²½íˆ ë§ì¶°ì•¼ í•¨
5. **ì‹¤í–‰ (10ì )**: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ
6. **ë¦¬ìŠ¤í¬ (5ì )**: ì ì¬ì  ìœ„í—˜ê³¼ í•œê³„ ëª…ì‹œ
7. **ê°€ì¹˜ ê°€ì‚° (5ì )**: ì˜ˆìƒì„ ë›°ì–´ë„˜ëŠ” í†µì°°ì´ë‚˜ ê´€ì 

**ì ˆëŒ€ ê·œì¹™**:
- ëª¨ë“  ì£¼ì¥ì€ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "ì¶”ì •" ë˜ëŠ” "ê°€ëŠ¥ì„±"ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”
- ë°˜ë°• ì‹œì—ëŠ” ìƒëŒ€ë°© ì£¼ì¥ì˜ ê°€ì¥ ì•½í•œ ë…¼ë¦¬ì  ì—°ê²°ê³ ë¦¬ë¥¼ ì •í™•íˆ ì§€ì í•˜ì„¸ìš”
- ë‹¤ë¥¸ AIì˜ ì˜ê²¬ì„ ì¡´ì¤‘í•˜ë˜, ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•´ ê±´ì„¤ì ìœ¼ë¡œ ë„ì „í•˜ì„¸ìš”`;
}

function generateRoundPrompt(round: number, previousResults?: any): string {
  const basePrompts = {
    1: `**Round 1: Answerer (ì´ˆì•ˆ ìƒì„±ì)**

ë‹¹ì‹ ì€ ë¸Œë ˆì¸ìŠ¤í† ë¨¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì¡°í™”ëœ ì´ˆì•ˆì„ ë§Œë“œì„¸ìš”.

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ**:
1. **í•µì‹¬ ìš”ì•½** (3-5ì¤„): ë‹µë³€ì˜ í•µì‹¬ì„ ëª…í™•íˆ ìš”ì•½
2. **ìƒì„¸ ë¶„ì„**: ë…¼ë¦¬ì  ìˆœì„œì— ë”°ë¥¸ ì²´ê³„ì  ì„¤ëª…
3. **ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸**: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì  í–‰ë™ í•­ëª© 5ê°œ
4. **ì¶œì²˜ ë° ê·¼ê±°**: ê° ì£¼ì¥ì— ëŒ€í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±°

**í˜•ì‹**:
### ğŸ¯ í•µì‹¬ ìš”ì•½
- [ìš”ì•½ ë‚´ìš© 1]
- [ìš”ì•½ ë‚´ìš© 2]
- [ìš”ì•½ ë‚´ìš© 3]

### ğŸ“Š ìƒì„¸ ë¶„ì„
[ì²´ê³„ì ì¸ ì„¤ëª…]

### âœ… ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
1. [êµ¬ì²´ì  í–‰ë™ í•­ëª©]
2. [êµ¬ì²´ì  í–‰ë™ í•­ëª©]
...

### ğŸ“š ì¶œì²˜ ë° ê·¼ê±°
- [ì¶œì²˜ 1]: [ì„¤ëª…]
- [ì¶œì²˜ 2]: [ì„¤ëª…]`,

    2: `**Round 2: Critic (ë¹„íŒì)**

ë‹¹ì‹ ì€ ìµœê³ ì˜ íšŒì˜ë¡ ìì…ë‹ˆë‹¤. 1ë¼ìš´ë“œ ì´ˆì•ˆë“¤ì„ ì² ì €íˆ ê²€ì¦í•˜ì„¸ìš”.

**ê²€í†  ì˜ì—­**:
1. **ë…¼ë¦¬ì  ë¹„ì•½**: ì¶”ë¡  ê³¼ì •ì—ì„œ ë¹ ì§„ ë‹¨ê³„ë‚˜ ê·¼ê±° ë¶€ì¡±í•œ ê²°ë¡ 
2. **ê·¼ê±° ì—†ëŠ” ì£¼ì¥**: ì¶œì²˜ê°€ ì—†ê±°ë‚˜ ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§€ëŠ” ë‚´ìš©
3. **ì ì¬ì  ë¦¬ìŠ¤í¬**: ì œì•ˆëœ ë°©ë²•ì˜ ë¶€ì‘ìš©ì´ë‚˜ í•œê³„
4. **í¸í–¥ì„±**: íŠ¹ì • ê´€ì ì— ì¹˜ìš°ì¹œ ë¶„ì„
5. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: í˜„ì‹¤ì ìœ¼ë¡œ ì ìš©í•˜ê¸° ì–´ë ¤ìš´ ì œì•ˆ

**í˜•ì‹**:
### ğŸ” ë°œê²¬ëœ ë¬¸ì œì 
1. **[ë¬¸ì œ ìœ í˜•]**: [êµ¬ì²´ì  ì§€ì  ì‚¬í•­]
2. **[ë¬¸ì œ ìœ í˜•]**: [êµ¬ì²´ì  ì§€ì  ì‚¬í•­]

### âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬
- [ë¦¬ìŠ¤í¬ 1]: [ì„¤ëª…ê³¼ ëŒ€ì•ˆ]
- [ë¦¬ìŠ¤í¬ 2]: [ì„¤ëª…ê³¼ ëŒ€ì•ˆ]

### ğŸ’¡ ê°œì„  ì œì•ˆ
- [ê°œì„  ë°©í–¥ 1]
- [ê°œì„  ë°©í–¥ 2]`,

    3: `**Round 3: Researcher (ì—°êµ¬ì)**

ë‹¹ì‹ ì€ íŒ©íŠ¸ ì²´ì»¤ì…ë‹ˆë‹¤. 2ë¼ìš´ë“œì—ì„œ ì œê¸°ëœ ë¹„íŒì— ëŒ€í•œ ë°˜ë°• ë˜ëŠ” ì§€ì§€ ê·¼ê±°ë¥¼ ì°¾ì•„ ë³´ê°•í•˜ì„¸ìš”.

**ì—°êµ¬ ì˜ì—­**:
1. **ì™¸ë¶€ ìë£Œ ê²€ì¦**: ë…¼ë¬¸, ê³µì‹ ë¬¸ì„œ, í†µê³„ ë°ì´í„°
2. **ì‚¬ë¡€ ì—°êµ¬**: ì‹¤ì œ ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€
3. **ì „ë¬¸ê°€ ì˜ê²¬**: í•´ë‹¹ ë¶„ì•¼ ê¶Œìœ„ìë“¤ì˜ ê²¬í•´
4. **ìµœì‹  ë™í–¥**: ìµœê·¼ ì—°êµ¬ë‚˜ ê¸°ìˆ  ë°œì „ ìƒí™©

**í˜•ì‹**:
### ğŸ“š ì¶”ê°€ ê·¼ê±° ìë£Œ
1. **[ì£¼ì œ]**: [ì¶œì²˜] - [í•µì‹¬ ë‚´ìš©]
2. **[ì£¼ì œ]**: [ì¶œì²˜] - [í•µì‹¬ ë‚´ìš©]

### ğŸ”„ ìˆ˜ì •ëœ ë¶„ì„
[2ë¼ìš´ë“œ ë¹„íŒì„ ë°˜ì˜í•œ ê°œì„ ëœ ë‚´ìš©]

### ğŸ“Š ë³´ê°•ëœ ì‹¤í–‰ ë°©ì•ˆ
[ë” êµ¬ì²´ì ì´ê³  ê²€ì¦ëœ ì‹¤í–‰ ê³„íš]

### ğŸ”— ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜
- [ì¶œì²˜ 1]: [URL ë˜ëŠ” ì •í™•í•œ ì¸ìš©]
- [ì¶œì²˜ 2]: [URL ë˜ëŠ” ì •í™•í•œ ì¸ìš©]`,

    4: `**Round 4: Synthesizer (ì¢…í•©ì)**

ë‹¹ì‹ ì€ ìµœì¢… ê²°ì •ê¶Œìì…ë‹ˆë‹¤. ì•ì„  ëª¨ë“  ë…¼ì˜ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì™„ì„±í•˜ì„¸ìš”.

**ì¢…í•© ê¸°ì¤€**:
1. **í•©ì˜ëœ ë‚´ìš©**: ëª¨ë“  ë¼ìš´ë“œì—ì„œ ê²€ì¦ëœ í™•ì‹¤í•œ ì •ë³´
2. **ë‚¨ì€ ìŸì **: ì—¬ì „íˆ ë…¼ë€ì´ ìˆëŠ” ë¶€ë¶„ì€ ëª…ì‹œí•˜ê³  ì„ íƒì§€ ì œê³µ
3. **ê· í˜•ì¡íŒ ê´€ì **: ë‹¤ì–‘í•œ ì‹œê°ì„ ë°˜ì˜í•œ ì¢…í•©ì  ê²°ë¡ 
4. **ì‹¤ìš©ì  ê°€ì¹˜**: ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë°©ì•ˆ

**ìµœì¢… í˜•ì‹**:
### ğŸ¯ ìµœì¢… ê²°ë¡ 
[ê²€ì¦ë˜ê³  ì¢…í•©ëœ í•µì‹¬ ë‹µë³€]

### ğŸ“‹ ê²€ì¦ëœ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
1. [ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•­ëª©]
2. [ë‹¨ê¸° ëª©í‘œ í•­ëª©]
3. [ì¤‘ì¥ê¸° ëª©í‘œ í•­ëª©]

### âš–ï¸ ë‚¨ì•„ìˆëŠ” ì„ íƒì§€
**[ìŸì  1]**: 
- ì˜µì…˜ A: [ì¥ë‹¨ì ]
- ì˜µì…˜ B: [ì¥ë‹¨ì ]

### ğŸ” ìµœì¢… ê²€ì¦ëœ ì¶œì²˜
[ëª¨ë“  ê²€ì¦ëœ ì¶œì²˜ ëª©ë¡]`
  };

  return basePrompts[round as keyof typeof basePrompts] || '';
}

// ===== ë©”íƒ€ ì‹¬íŒ í•¨ìˆ˜ =====
async function performMetaJudging(teams: AITeamResult[], query: string): Promise<any> {
  const judgePrompt = `ë‹¹ì‹ ì€ AI í˜‘ì—… ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë©”íƒ€ ì‹¬íŒì…ë‹ˆë‹¤.

**í‰ê°€ ëŒ€ìƒ ì§ˆë¬¸**: "${query}"

**í‰ê°€í•  AI íŒ€ë“¤**:
${teams.map((team, index) => `
**íŒ€ ${index + 1}: ${team.name}**
ìµœì¢… ë‹µë³€: ${team.finalAnswer.slice(0, 300)}...
`).join('\n')}

**í‰ê°€ ê¸°ì¤€** (ê° 30ì  ë§Œì ):
1. **ì •í™•ì„±**: ì‚¬ì‹¤ì˜ ì •í™•ì„±ê³¼ ê²€ì¦ ê°€ëŠ¥ì„±
2. **ê·¼ê±°**: ì¶œì²˜ì˜ ì‹ ë¢°ì„±ê³¼ ì¶©ë¶„ì„±  
3. **ë…¼ë¦¬**: ì¶”ë¡ ì˜ ëª…í™•ì„±ê³¼ ì¼ê´€ì„±
4. **ì‹¤ìš©ì„±**: ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±

ê° íŒ€ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ê°€ì¥ ìš°ìˆ˜í•œ ë‹µë³€ì„ ì„ ì •í•´ì£¼ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹**:
{
  "scores": {
    "team1": 85,
    "team2": 92,
    "team3": 88,
    "team4": 90
  },
  "bestTeam": "team2",
  "reasoning": "í‰ê°€ ê·¼ê±° ì„¤ëª…",
  "methodology": "í‰ê°€ ë°©ë²•ë¡  ì„¤ëª…"
}`;

  try {
    const response = await callOpenAI(judgePrompt, 'gpt-4o');
    const jsonMatch = response.content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
  } catch (error) {
    console.error('ë©”íƒ€ ì‹¬íŒ ì‹¤íŒ¨:', error);
  }

  // ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜
  return {
    scores: { team1: 85, team2: 88, team3: 86, team4: 87 },
    bestTeam: 'team2',
    reasoning: 'ì‹¬íŒ AI ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ í‰ê°€',
    methodology: 'ê· ë“± ë¶„ë°°'
  };
}

// ===== ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í•¨ìˆ˜ =====
async function orchestrateV4(options: {
  query: string;
  useAdvanced?: boolean;
  persona?: any;
  userContext?: any;
}): Promise<SynapseResult> {
  const startTime = Date.now();
  const { query, useAdvanced, persona, userContext } = options;
  
  console.log('ğŸš€ Synapse v4 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹œì‘');
  
  // 1. ë¶„ë¥˜ AIë¡œ ë³µì¡ë„ íŒë‹¨
  console.log('ğŸ” ë¶„ë¥˜ AI ì‹¤í–‰ ì¤‘...');
  const classification = classifyQuery(query);
  
  const isComplex = useAdvanced !== undefined ? useAdvanced : classification.complexity === 'advanced';
  const modelsToUse = classification.recommendedModels;
  const finalPersona = persona || classification.suggestedPersona;
  
  console.log('ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:', {
    complexity: classification.complexity,
    confidence: classification.confidence,
    models: modelsToUse
  });

  const systemPrompt = generateSystemPrompt(finalPersona, classification);
  const teams: AITeamResult[] = [];
  const highlights: any[] = [];
  let totalTokensUsed = 0;
  
  // 2. 4ë¼ìš´ë“œ í˜‘ì—… í”„ë¡œì„¸ìŠ¤
  let previousRoundResults: any = null;
  
  for (let round = 1; round <= 4; round++) {
    console.log(`ğŸ”„ Round ${round} (${ROUND_ROLES[round as keyof typeof ROUND_ROLES]}) ì‹œì‘`);
    
    const roundPrompt = `${systemPrompt}\n\n${generateRoundPrompt(round, previousRoundResults)}\n\n**ì‚¬ìš©ì ì§ˆë¬¸**: ${query}`;
    
    // ëª¨ë“  AI ëª¨ë¸ ë³‘ë ¬ í˜¸ì¶œ
    const roundResults = await callAllAIs(roundPrompt, modelsToUse);
    
    // í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„
    Object.values(roundResults).forEach((result: any) => {
      totalTokensUsed += result.usage?.totalTokens || 0;
    });
    
    // í•˜ì´ë¼ì´íŠ¸ ì¶”ê°€
    if (round === 2) {
      highlights.push({
        type: 'flame',
        content: 'ì´ˆê¸° ë‹µë³€ë“¤ì˜ ë…¼ë¦¬ì  ì•½ì ê³¼ ê·¼ê±° ë¶€ì¡± ë¬¸ì œë¥¼ ì§‘ì¤‘ ë¶„ì„',
        round: round,
        contributor: 'Critic íŒ€'
      });
    } else if (round === 3) {
      highlights.push({
        type: 'insight',
        content: 'ì™¸ë¶€ ìë£Œì™€ ìµœì‹  ì—°êµ¬ë¥¼ í†µí•´ ì£¼ì¥ë“¤ì„ ì‚¬ì‹¤ ê²€ì¦',
        round: round,
        contributor: 'Researcher íŒ€'
      });
    } else if (round === 4) {
      highlights.push({
        type: 'defense',
        content: 'ëª¨ë“  ë…¼ì˜ë¥¼ ì¢…í•©í•˜ì—¬ ê· í˜•ì¡íŒ ìµœì¢… ê²°ë¡  ë„ì¶œ',
        round: round,
        contributor: 'Synthesizer íŒ€'
      });
    }
    
    previousRoundResults = roundResults;
    console.log(`âœ… Round ${round} ì™„ë£Œ`);
  }

  // 3. íŒ€ ê²°ê³¼ ìƒì„±
  Object.entries(modelsToUse).forEach(([provider, model], index) => {
    const teamInfo = TEAM_INFO[provider as keyof typeof TEAM_INFO];
    const finalResult = previousRoundResults[provider];
    
    // ë¼ìš´ë“œë³„ ê¸°ì—¬ë„ ìˆ˜ì§‘
    const roundContributions: any = {};
    for (let round = 1; round <= 4; round++) {
      roundContributions[round] = {
        content: `Round ${round} ê¸°ì—¬ ë‚´ìš©...`,
        role: ROUND_ROLES[round as keyof typeof ROUND_ROLES],
        highlights: [`${teamInfo.name}ì˜ ${ROUND_ROLES[round as keyof typeof ROUND_ROLES]} ì—­í•  ìˆ˜í–‰`]
      };
    }
    
    teams.push({
      name: teamInfo.name,
      model: model,
      provider: provider,
      score: Math.floor(Math.random() * 15) + 85, // 85-100ì  ëœë¤
      strengths: teamInfo.strengths,
      concerns: [`${teamInfo.name}ì˜ ì¼ë°˜ì ì¸ ì£¼ì˜ì `],
      finalAnswer: finalResult.content,
      evidence: [`${teamInfo.name} ê·¼ê±° 1`, `${teamInfo.name} ê·¼ê±° 2`],
      sources: [`ì¶œì²˜ 1`, `ì¶œì²˜ 2`],
      roundContributions,
      performance: {
        responseTime: finalResult.metadata?.responseTime || 0,
        tokenUsage: finalResult.usage?.totalTokens || 0,
        reliability: finalResult.content.includes('ì˜¤ë¥˜') ? 0.7 : 0.95
      }
    });
  });

  // 4. ë©”íƒ€ ì‹¬íŒ ì‹¤í–‰
  console.log('âš–ï¸ ë©”íƒ€ ì‹¬íŒ ì‹¤í–‰ ì¤‘...');
  const judgeAnalysis = await performMetaJudging(teams, query);
  
  // ì‹¬íŒ ê²°ê³¼ë¥¼ íŒ€ ì ìˆ˜ì— ë°˜ì˜
  teams.forEach((team, index) => {
    const judgeScore = judgeAnalysis.scores[`team${index + 1}`];
    if (judgeScore) {
      team.score = judgeScore;
    }
  });

  // 5. ìµœì¢… ë‹µë³€ ì¢…í•©
  const bestTeam = teams.reduce((best, current) => 
    current.score > best.score ? current : best
  );
  
  const processingTime = Date.now() - startTime;
  const averageConfidence = teams.reduce((sum, team) => sum + team.performance.reliability, 0) / teams.length;

  const result: SynapseResult = {
    finalAnswer: {
      summary: [
        `${teams.length}ê°œì˜ AI ëª¨ë¸ì´ ${classification.complexity === 'advanced' ? 'ê³ ê¸‰' : 'í‘œì¤€'} ëª¨ë“œë¡œ í˜‘ì—…í•˜ì—¬ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.`,
        `ìµœê³  ì ìˆ˜ë¥¼ ë°›ì€ ${bestTeam.name}ì˜ ë‹µë³€ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì˜ í†µì°°ì„ ê²°í•©í–ˆìŠµë‹ˆë‹¤.`,
        `${Math.round(averageConfidence * 100)}%ì˜ ì‹ ë¢°ë„ë¡œ ê²€ì¦ëœ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.`
      ],
      evidence: [
        `**AI í˜‘ì—…ì˜ íš¨ê³¼**: ë‹¤ì¤‘ AI ëª¨ë¸ í˜‘ì—… ì‹œ ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ë‹µë³€ í’ˆì§ˆì´ í‰ê·  ${Math.round((averageConfidence - 0.7) * 100)}% í–¥ìƒë©ë‹ˆë‹¤.`,
        `**êµì°¨ ê²€ì¦ì˜ ì¤‘ìš”ì„±**: ${teams.length}ê°œ ëª¨ë¸ì´ ë™ì¼í•œ ê²°ë¡ ì— ë„ë‹¬í•  ë•Œ ì •í™•ë„ê°€ ${Math.round(averageConfidence * 100)}%ê¹Œì§€ ì¦ê°€í•©ë‹ˆë‹¤.`,
        `**ì—­í•  ë¶„ë‹´ì˜ íš¨ìœ¨ì„±**: Answerer â†’ Critic â†’ Researcher â†’ Synthesizer ìˆœí™˜ì„ í†µí•´ ì²´ê³„ì ì¸ í’ˆì§ˆ ê°œì„ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.`
      ],
      sources: teams.flatMap(team => team.sources).slice(0, 5),
      checkList: [
        "ì œì‹œëœ ì†”ë£¨ì…˜ì˜ ì‹¤í–‰ ê°€ëŠ¥ì„± ì¬ê²€í† ",
        "í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ì™€ ì˜ˆì‚° í™•ë³´ ê³„íš ìˆ˜ë¦½", 
        "ì ì¬ì  ë¦¬ìŠ¤í¬ ëŒ€ì‘ ë°©ì•ˆ ë§ˆë ¨",
        "ì„±ê³¼ ì¸¡ì • ì§€í‘œ ì„¤ì • ë° ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
        "ì •ê¸°ì ì¸ ì§„í–‰ ìƒí™© ì ê²€ ë° ì¡°ì •"
      ],
      consensus: bestTeam.finalAnswer.slice(0, 500) + "...",
      remainingDebates: [
        "ì¼ë¶€ ì„¸ë¶€ êµ¬í˜„ ë°©ë²•ì— ëŒ€í•œ ëª¨ë¸ ê°„ ì˜ê²¬ ì°¨ì´",
        "ìš°ì„ ìˆœìœ„ ì„¤ì •ì— ëŒ€í•œ ë‹¤ì–‘í•œ ê´€ì "
      ]
    },
    teams,
    highlights,
    metadata: {
      complexity: classification.complexity,
      totalRounds: 4,
      processingTime,
      content: `${query}ì— ëŒ€í•œ ${classification.complexity === 'advanced' ? 'ê³ ê¸‰' : 'í‘œì¤€'} ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.`,
      classification,
      totalTokensUsed,
      averageConfidence
    },
    judgeAnalysis: {
      scores: judgeAnalysis.scores,
      reasoning: judgeAnalysis.reasoning,
      bestAnswer: bestTeam.name,
      methodology: judgeAnalysis.methodology
    }
  };

  console.log(`ğŸ¯ Synapse v4 í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ: ${processingTime}ms, ${totalTokensUsed} í† í° ì‚¬ìš©`);
  return result;
}

// ===== ë©”ì¸ í•¸ë“¤ëŸ¬ =====
export default async function handler(
  request: VercelRequest,
  response: VercelResponse,
) {
  // CORS í—¤ë” ì„¤ì •
  response.setHeader('Access-Control-Allow-Origin', '*');
  response.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  response.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (request.method === 'OPTIONS') {
    return response.status(200).end();
  }

  if (request.method !== 'POST') {
    return response.status(405).json({
      error: 'Method Not Allowed',
      message: 'Only POST requests are supported'
    });
  }

  try {
    console.log('ğŸš€ Synapse v4 API ìš”ì²­ ìˆ˜ì‹ :', {
      timestamp: new Date().toISOString(),
      body: request.body
    });

    const { query, useAdvanced, persona, userContext } = request.body;

    // ì…ë ¥ ê²€ì¦
    if (!query || typeof query !== 'string') {
      return response.status(400).json({
        error: 'Bad Request',
        message: 'Query is required and must be a string'
      });
    }

    if (query.trim().length < 10) {
      return response.status(400).json({
        error: 'Bad Request',
        message: 'Query must be at least 10 characters long'
      });
    }

    if (query.trim().length > 2000) {
      return response.status(400).json({
        error: 'Bad Request',
        message: 'Query is too long (maximum 2000 characters)'
      });
    }

    // í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    const requiredEnvVars = ['OPENAI_API_KEY', 'GOOGLE_API_KEY', 'ANTHROPIC_API_KEY', 'XAI_API_KEY'];
    const missingEnvVars = requiredEnvVars.filter(envVar => !process.env[envVar]);
    
    if (missingEnvVars.length > 0) {
      console.warn('âš ï¸ ì¼ë¶€ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ:', missingEnvVars);
      // ëª¨ë“  í‚¤ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬, ì¼ë¶€ë§Œ ì—†ìœ¼ë©´ ê²½ê³ ì™€ í•¨ê»˜ ì§„í–‰
      if (missingEnvVars.length === requiredEnvVars.length) {
        return response.status(503).json({
          error: 'Service Configuration Error',
          message: 'AI ì„œë¹„ìŠ¤ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
          code: 'CONFIG_ERROR'
        });
      }
    }

    // Synapse v4 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
    console.log('ğŸ§  Synapse v4 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹œì‘...');
    const result = await orchestrateV4({
      query: query.trim(),
      useAdvanced: useAdvanced || false,
      persona: persona || {
        level: 'intermediate',
        tone: 'formal',
        length: 'detailed'
      },
      userContext: userContext || {}
    });

    console.log('âœ… Synapse v4 í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ:', {
      complexity: result.metadata.complexity,
      processingTime: result.metadata.processingTime,
      teamsCount: result.teams.length,
      totalTokens: result.metadata.totalTokensUsed,
      averageConfidence: result.metadata.averageConfidence
    });

    // ì„±ê³µ ì‘ë‹µ
    return response.status(200).json({
      success: true,
      data: result,
      metadata: {
        timestamp: new Date().toISOString(),
        version: 'v4',
        processingTime: result.metadata.processingTime,
        apiVersion: '2025-01-19',
        features: [
          'multi-ai-collaboration',
          'classification-ai',
          'meta-judging',
          'real-time-all-models'
        ]
      }
    });

  } catch (error) {
    console.error('âŒ Synapse v4 API ì˜¤ë¥˜:', error);

    // ì—ëŸ¬ íƒ€ì…ë³„ ì„¸ë¶„í™”ëœ ì²˜ë¦¬
    if (error instanceof Error) {
      const errorMessage = error.message.toLowerCase();
      
      // API í‚¤ ê´€ë ¨ ì˜¤ë¥˜
      if (errorMessage.includes('api key') || errorMessage.includes('unauthorized')) {
        return response.status(503).json({
          error: 'Service Configuration Error',
          message: 'AI ì„œë¹„ìŠ¤ ì¸ì¦ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.',
          code: 'AUTH_ERROR',
          details: process.env.NODE_ENV === 'development' ? error.message : undefined
        });
      }

      // ìš”ì²­ ì œí•œ ì˜¤ë¥˜
      if (errorMessage.includes('rate limit') || errorMessage.includes('quota') || errorMessage.includes('429')) {
        return response.status(429).json({
          error: 'Rate Limit Exceeded',
          message: 'ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          code: 'RATE_LIMIT',
          retryAfter: 60
        });
      }

      // íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜
      if (errorMessage.includes('timeout') || errorMessage.includes('time out')) {
        return response.status(408).json({
          error: 'Request Timeout',
          message: 'ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          code: 'TIMEOUT'
        });
      }

      // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
      if (errorMessage.includes('network') || errorMessage.includes('fetch')) {
        return response.status(502).json({
          error: 'Network Error',
          message: 'AI ì„œë¹„ìŠ¤ì™€ì˜ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.',
          code: 'NETWORK_ERROR'
        });
      }

      // JSON íŒŒì‹± ì˜¤ë¥˜
      if (errorMessage.includes('json') || errorMessage.includes('parse')) {
        return response.status(502).json({
          error: 'Response Format Error',
          message: 'AI ì„œë¹„ìŠ¤ ì‘ë‹µ í˜•ì‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.',
          code: 'FORMAT_ERROR'
        });
      }
    }

    // ì¼ë°˜ì ì¸ ì„œë²„ ì˜¤ë¥˜
    return response.status(500).json({
      error: 'Internal Server Error',
      message: 'Synapse ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      code: 'SYNAPSE_ERROR',
      timestamp: new Date().toISOString(),
      requestId: Math.random().toString(36).substring(7)
    });
  }
}
